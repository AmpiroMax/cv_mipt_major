{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Работа с растровыми изображенями**\n",
    "**Растровое изображение** $-$ изображение, представляющее собой сетку пикселей — цветных точек. \n",
    "Важными характеристиками изображения являются: размер, глубина цвета и цветовое пространство.\n",
    "\n",
    "<img src=\"img/RGB_cube.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Самый распространённый способ выделить объект $-$ это цвет.\n",
    "\n",
    "**Цвет** $-$ это свойство тел отражать или испускать видимое излучение определенного спектрального состава и интенсивности.\n",
    "\n",
    "Трихроматическая теория (сетчатка глаза имеет 3 вида рецепторов света, ответственных за цветное зрение) полагает, что достаточно всего трёх чисел, чтобы описать цвет (красный, синий, зелёный). Т.е. используя три значения **R, G, B**  \n",
    "\n",
    "Цветовые пространства бывают линейные и нелинейные.\n",
    "К линейным относится **RGB**. Изучим его подробней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T14:28:15.375650Z",
     "start_time": "2021-02-08T14:28:14.133535Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# отображение графиков в ноутбуке\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T14:28:15.807761Z",
     "start_time": "2021-02-08T14:28:15.780233Z"
    }
   },
   "outputs": [],
   "source": [
    "# считаем изображение\n",
    "image = cv2.imread('img/RGB_cube.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T14:28:16.091281Z",
     "start_time": "2021-02-08T14:28:16.085274Z"
    }
   },
   "outputs": [],
   "source": [
    "# посмотрим, какой тип объекта \n",
    "type(image), image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T14:28:16.865202Z",
     "start_time": "2021-02-08T14:28:16.861216Z"
    }
   },
   "outputs": [],
   "source": [
    "# размерность\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T14:28:17.160851Z",
     "start_time": "2021-02-08T14:28:17.018807Z"
    }
   },
   "outputs": [],
   "source": [
    "# преобразуем RGB в BGR для корректного отображения\n",
    "# это необходимо из-за особенностей matplotlib\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# отобразим объект\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale\n",
    "\n",
    "**Grayscale** - цветовой режим изображений, которые отображаются в оттенках серого цвета, размещённые в виде таблицы в качестве эталонов яркости белого цвета.\n",
    "\n",
    "В компьютерном представлении широко распространённая серая шкала использует на каждый пиксел изображения один байт ($8$ бит) информации. Такая шкала передаёт $256$ оттенков (градаций) серого цвета, или яркости (значение $0$ представляет чёрный цвет, а значение $255$ $-$ белый).\n",
    "\n",
    "<img src=\"img/grad_grayscale.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Преобразование цветного изображения в оттенки серого из **RGB** пересчитывают по формуле:\n",
    "\n",
    "\\begin{align}\n",
    "\\ Y' & = 0.2126R + 0.7152G + 0.0722B \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **OpenCV_** сменить цветовой режим изображения можно с помощью функции **cv2.cvtColor(img, code)**\n",
    "\n",
    "* **img** $-$ исходное изображение\n",
    "* **code** $-$ кодировка для смены цвета. \n",
    "\n",
    "Все кодировки есть в [документации](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab). В рамках занятий мы рассмотрим лишь их часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:55:04.198197Z",
     "start_time": "2020-09-26T16:55:03.893194Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим grayscale изображение с помощью openCV\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 8))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "ax1.set_title('RGB изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax2.set_title('Grayscale изображение', fontsize=15)\n",
    "ax2.imshow(gray_image, cmap='gray')\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиграемся с каналами\n",
    "Выделим каналы изображения. Они представимы как массивы чисел, поэтому не составит труда их разделить из исходного изобрадения. Посмоторим на картинку, где есть только красный, зеленый и синий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:59:17.387503Z",
     "start_time": "2020-09-26T16:59:17.378980Z"
    }
   },
   "outputs": [],
   "source": [
    "# R scale\n",
    "r = image[:, :, 0].copy()\n",
    "r[(r >= 30) & (r <= 250)] = 0\n",
    "\n",
    "# G scale\n",
    "g = image[:, :, 1].copy()\n",
    "g[(g >= 150) & (g <= 250)] = 0\n",
    "\n",
    "# B scale\n",
    "b = image[:, :, 2].copy()\n",
    "b[(b >= 250) & (b <= 255)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:59:18.125460Z",
     "start_time": "2020-09-26T16:59:17.803160Z"
    }
   },
   "outputs": [],
   "source": [
    "## посмотрим на результат\n",
    "fig, axs = plt.subplots(1, 4, figsize = (20, 9))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "ax1.set_title('R канал', fontsize=15)\n",
    "ax1.imshow(r, cmap='gray')\n",
    "ax2.set_title('G канал', fontsize=15)\n",
    "ax2.imshow(g, cmap='gray')\n",
    "ax3.set_title('B канал', fontsize=15)\n",
    "ax3.imshow(b, cmap='gray')\n",
    "ax4.set_title('RGB', fontsize=15)\n",
    "ax4.imshow(image)\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Контрольные вопросы:***\n",
    "\n",
    "1. Почему так получилось?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте изменим конфигурацию каналов, чтобы посмотреть на изменения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:01:13.523384Z",
     "start_time": "2020-09-26T17:01:13.516381Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_val = 155  # пороговое значение\n",
    "\n",
    "# R scale\n",
    "r = image[:, :, 2].copy()\n",
    "r[r < tr_val] = 0\n",
    "\n",
    "# G scale\n",
    "g = image[:, :, 1].copy()\n",
    "g[g < tr_val] = 0\n",
    "\n",
    "# B scale\n",
    "b = image[:, :, 0].copy()\n",
    "b[b < tr_val] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:01:14.509645Z",
     "start_time": "2020-09-26T17:01:14.195498Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## посмотрим на результат\n",
    "fig, axs = plt.subplots(1, 4, figsize = (20, 9))\n",
    "ax1, ax2, ax3, ax4 = axs\n",
    "\n",
    "ax1.set_title('R канал', fontsize=15)\n",
    "ax1.imshow(r, cmap='gray')\n",
    "ax2.set_title('G канал', fontsize=15)\n",
    "ax2.imshow(g, cmap='gray')\n",
    "ax3.set_title('B канал', fontsize=15)\n",
    "ax3.imshow(b, cmap='gray')\n",
    "ax4.set_title('RGB', fontsize=15)\n",
    "ax4.imshow(image)\n",
    "\n",
    "axs = [ax.axis('off') for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Контрольные вопросы:***\n",
    "\n",
    "1. Какой вывод можно сделать из этих примеров?\n",
    "\n",
    "2. Чем неудобна **RGB** кодировка цвета?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск по цвету"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывают задачи, в которых отличительной особенностью предмета являтются его цветовые признаки. Рассмотрим пример:\n",
    "\n",
    "<img src=\"img/cat.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Как мы можем в этом найти кота? Для начала мы можем оценить глазами, что цвет кота отличается от цвета окружения – он ярко рыжий и отлично виден в траве. Как мы можем выделить этот цвет в OpenCV? Для этого существует специальная функция ```cv2.inRange(image, low_color, max_color)```, она принимает на вход изображение и диапазон цвета, который мы хотим выделить. **На выходе мы получаем черно-белое изображение**, где белым выделены пиксели, цвета которых попадали в диапазон, а черным $-$ все другое. Дальше мы попробуем найти кота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найди кота\n",
    "\n",
    "Теперь попробуем найти кота на изображении с помощью реализованного поиска цвета выше. Одако вот так искать цвет для конкретного объекта в цветом пространстве RGB трудно. Рассмотрим пример для наглядности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:10:44.281106Z",
     "start_time": "2020-09-26T17:10:23.955321Z"
    }
   },
   "outputs": [],
   "source": [
    "# посмторим на кота\n",
    "\n",
    "cat_image  = cv2.imread('img/cat.jpg')\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('cat', cat_image)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:11:32.098357Z",
     "start_time": "2020-09-26T17:11:31.906789Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_image  = cv2.imread('img/cat.jpg')\n",
    "\n",
    "# значения цвета можно посмотреть в gimp или paint\n",
    "pix = 256\n",
    "low_red = (0.0 * pix, 0.11 * pix, 0.37 * pix)\n",
    "high_red = (0.35 * pix, 0.4 * pix, 0.99 * pix)\n",
    "\n",
    "cat_area = cv2.inRange(cat_image, low_red, high_red)\n",
    "\n",
    "# посмотрим на результат\n",
    "fig, m_axs = plt.subplots(1, 2, figsize = (12, 9))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходная картинка', fontsize=15)\n",
    "cat_image = cv2.cvtColor(cat_image, cv2.COLOR_BGR2RGB)  # преобразуем цвет для plt\n",
    "ax1.imshow(cat_image, cmap='gray')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.set_title('Только кот', fontsize=15)\n",
    "ax2.imshow(cat_area, cmap='gray')\n",
    "ax2.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:17:50.256834Z",
     "start_time": "2020-09-26T17:17:50.050240Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_idx = np.argwhere(cat_area == 255)\n",
    "\n",
    "only_cat = np.zeros_like(cat_image)\n",
    "for (x, y) in cat_idx:\n",
    "    only_cat[x, y] = cat_image[x,y]\n",
    "    \n",
    "plt.imshow(only_cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:24:35.502361Z",
     "start_time": "2020-09-26T17:24:35.338675Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = cat_idx.T\n",
    "only_cat = np.zeros_like(cat_image)\n",
    "\n",
    "only_cat[x, y] = cat_image[x, y]\n",
    "\n",
    "plt.imshow(only_cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кот в RGB $-$ не кот. Выбираем цветовое пространство.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С данным изображением мы уже можем работать, но что-то в нем не то. Кот выделен не целиком, и есть много лишних точек. На самом деле, мы научимся даже из такого получать много полезной информации, но в данный момент мы сделаем одно очень важное и правильное улучшение. Как вы могли заметить $-$ мы работаем с изображением в пространстве **RGB**. У данного пространства, кроме не очевидной для человеческого восприятия записи цвета, есть еще один недостаток в нашем случае. Чтобы его понять, рассмотрим что из себя представляет **RGB**:\n",
    "\n",
    "<img src=\"img/RGB_cube_scheme.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пространство представляет из себя куб с длинной стороны $256$, где любой цвет задается координатами соответствующей точки на данном кубе. Данная концепция получила широкое распространение из-за того, что в случае формирования цвета на экране устройства, такого как телефон или монитор компьютера, изображение формируется за счет точек трех цветов $-$ синего, зеленого, и красного. Теперь перейдем к нашей функции ```cv2.inRange()```. Она принимает набор из двух цветов – точек на данном кубе. Что в таком случае мы будем считать за цвет, который удовлетворяет нашим критериям? Для ответа на данный вопрос нарисуем схематично тот же самый куб RGB:\n",
    "\n",
    "<img src=\"img/RGB_scheme.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данной схеме становится понятно, что пространство между двумя заданными точками цвета также является кубом RGB. Таким образом, наша функция находит вложенный цветовой куб в полном кубе RGB. Кроме того, что это может непонятно звучать, это и работает не самым лучшим образом: представим что мы хотим найти оттенки пурпурного цвета, в таком случае мы размещаем наш вложенный куб как можно ближе к пурпурному. Но при таком размещении, мы так или иначе затрагиваем все остальные цвета, из-за того, что стороны куба параллельны основному. Как в таком случае поступить?\n",
    "\n",
    "Мы не первые,кто сталкивается с такой задачей и такой проблемой. И одно из существующих решений $-$ переход в другое цветовое пространство. Если поставить задачей, что во главе угла у нас фиксируется оттенок цвета или соотношение между RGB, то мы приходим к следующей схеме:\n",
    "\n",
    "<img src=\"img/RGB_HSV_trans.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной модели мы переходим к следующим координатам $-$ **оттенок, насыщенность и значение**. Именно в данных понятиях люди обычно описывают цвета. \n",
    "\n",
    "Под цветовым тоном (**Hue**) имеют в виду именно цвет (длину волны). \n",
    "\n",
    "Насыщенность (**Saturation**) характеризует близость цвета к белому (розовый ближе к белому чем красный). \n",
    "\n",
    "Значение (**Value**) описывается всех сложнее и в модели HS ее можно описать как общую яркость точки или цвета.\n",
    "\n",
    "Все серые цвета (лежащие на диагонали куба) при этом проецируются в центральную точку. Чтобы с помощью этой модели можно было закодировать все цвета, доступные в RGB-модели, необходимо добавить вертикальную ось яркости (или интенсивности) (I). В итоге получается:\n",
    "\n",
    "<img src=\"img/HSV.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "В OpenCV диапазоны разные. S, V находятся в $[0,255]$, а H – в $[0,180]$. Обычно H находится в диапазоне $[0,360]$ (полный круг), но для того, чтобы поместиться в байте ($256$ различных значений), его значение уменьшается вдвое.\n",
    "\n",
    "В пространстве HSV проще отделить один цвет, так как вы можете просто установить правильный диапазон для H и просто позаботиться о том, чтобы S не был слишком маленьким (он будет почти белым), а V не слишком мал (это будет темно).\n",
    "\n",
    "Например, если вам нужны почти синие цвета, вам нужно, чтобы H находилось вокруг значения $120$ (например, в $[110,130]$), а S, V не слишком мало (скажем, в $[100, 255]$).\n",
    "\n",
    "Белый цвет не является оттенком (радуга не имеет белого цвета в нем), но представляет собой комбинацию цвета.\n",
    "\n",
    "В HSV вам нужно взять весь диапазон H (H в $[0, 180]$), очень малые значения S (например, S в $[0, 25]$) и очень высокие значения V (например, V в $[230, 255]$). Это в основном соответствует верхней части центральной оси конуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном конусе диапазон выбранных цветов будет представлять из себя конический слой. Его главные для нас атрибуты: он лежит по оттенку в заданных пределах, в отличии от RGB, его светлота и интенсивность также определяются просто и очевидно в описании цветового предела. Благодаря таким удобным и полезным свойствам данное цветовое пространство заслужило большую любовь как среди дизайнеров, так и особенно среди общества разработчиков компьютерного зрения. \n",
    "\n",
    "В OpenCV данное цветовое пространство имеет обозначение **HSV**. Переведем наше изображение в него и снова найдем котейку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:32:51.143559Z",
     "start_time": "2020-09-26T17:32:50.794486Z"
    }
   },
   "outputs": [],
   "source": [
    "# меняем цветовое пространство\n",
    "cat_image_hsv = cv2.cvtColor(cat_image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# осталось только подобрать нужные цвета \n",
    "# воспользуйтесь функциями, которые реализовали выше\n",
    "hsv_low = (0.0 * 360, 60, 60)\n",
    "hsv_high = (0.06 * 360, 250, 255)\n",
    "\n",
    "cat_area = cv2.inRange(cat_image_hsv, hsv_low, hsv_high)\n",
    "\n",
    "## посмотрим на результат\n",
    "fig, m_axs = plt.subplots(1, 2, figsize = (12, 9))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходная картинка', fontsize=15)\n",
    "ax1.imshow(cat_image, cmap='gray')\n",
    "ax2.set_title('Только кот', fontsize=15)\n",
    "ax2.imshow(cat_area, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:33:22.657644Z",
     "start_time": "2020-09-26T17:33:22.475492Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_idx = np.argwhere(cat_area == 255)\n",
    "x, y = cat_idx.T\n",
    "only_cat = np.zeros_like(cat_image)\n",
    "\n",
    "only_cat[x, y] = cat_image[x, y]\n",
    "\n",
    "plt.imshow(only_cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут я лишь остановлюсь на моменте выбора цвета, в данном примере мы руководствовались лишь собственным глазом и оценкой того, какой цвет мы хотим найти. Этим **HSV** замечательно отличается от **RGB**, в которой нам необходимо каждый цвет искать в справочнике или использовать сторонние программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Геометрические преобразования изображений**\n",
    "\n",
    "Теперь мы рассмотрим каким образом аффинные преобразования помогут нам изменять изображения с помощью OpenCV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однородные координаты\n",
    "\n",
    "А что же делать? Колдовать! Представьте теперь, что я допишу руками одну строчку и один столбец к нашей матрице преобразования и добавлю третью координату, которая равна единице у вектора, который мы преобразовываем:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} a && b && e\\\\ c && d && f\\\\ 0 && 0 && 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} ax + by + e \\\\ cx + dy + f \\\\ 1 \\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "При умножении этой 3x3 матрицы и нашего вектора, дополненного единицей, мы снова получили вектор с единицей в третьей компоненте, а остальные две имеют ровно тот вид, который мы хотели! Колдунство.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сдвиг изображения\n",
    "**Сдвиг** $-$ это смещение местоположения объекта. Если вам известно смещение в направлении $(x,y)$, пусть оно будет $(tx,ty)$, вы можете создать матрицу преобразования $M$ следующим образом:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "1 & \\ 0 & \\ t_x \\\\ \n",
    "0 & \\ 1 & \\ t_y \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Затем вы можете взять массив Numpy типа np.float32 и передать его в функцию **cv2.warpAffine()**. Ниже приведен пример сдвига:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:40:37.742925Z",
     "start_time": "2020-09-26T17:40:37.160509Z"
    }
   },
   "outputs": [],
   "source": [
    "# сдвиг изображения\n",
    "\n",
    "image  = cv2.imread('img/RGB_cube.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "## посмотрим на размер изображения\n",
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "## матрица афинного преобразования\n",
    "M1 = np.float32([[1, 0, 200], [0, 1, 0]])\n",
    "M2 = np.float32([[1, 0, 0], [0, 1, 200]])\n",
    "M3 = np.float32([[1, 0, 200], [0, 1, 200]])\n",
    "\n",
    "## визуализация\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20,8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "dst1 = cv2.warpAffine(image.copy(), M1, (cols * 2, rows))\n",
    "ax1.imshow(dst1)\n",
    "ax1.grid()\n",
    "ax1.set_title('M1 преоразование', fontsize=15)\n",
    "\n",
    "dst2 = cv2.warpAffine(image.copy(), M2, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "ax2.set_title('M2 преоразование', fontsize=15)\n",
    "\n",
    "dst3 = cv2.warpAffine(image.copy(), M3, (cols, rows))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid()\n",
    "ax3.set_title('M3 преоразование', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поворот изображения\n",
    "Поворот изображения на угол $\\theta$ достигается путем преобразования матрицы вида:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "\\cos(\\theta) & \\ -\\sin(\\theta) \\\\ \n",
    "\\sin(\\theta) & \\ \\cos(\\theta) \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Но OpenCV обеспечивает масштабированное вращение с регулируемым центром вращения, так что вы можете вращаться в любом месте, которое вы предпочитаете. Модифицированная матрица преобразования задается:\n",
    "\n",
    "$$\n",
    "\\ M = \\begin{pmatrix}\n",
    "\\alpha & \\ -\\beta & \\ (1-\\alpha)\\cdot center.x - \\beta \\cdot center.y \\\\ \n",
    "\\beta & \\ \\alpha & \\ \\beta \\cdot center/x + (1-\\alpha) \\cdot center.y \\\\  \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "где: \n",
    "\n",
    "$$\n",
    "\\alpha = scale \\cdot \\cos(\\theta) \\\\\n",
    "\\beta = scale \\cdot \\sin(\\theta) \\\\ \n",
    "$$ \n",
    "\n",
    "Результатом поворота является:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\ x' \\\\ \\ y' \\\\ \\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "\\alpha & \\ -\\beta & \\ (1-\\alpha)\\cdot center.x - \\beta \\cdot center.y \\\\ \n",
    "\\beta & \\ \\alpha & \\ \\beta \\cdot center/x + (1-\\alpha) \\cdot center.y \\\\ \n",
    "\\end{pmatrix} \\cdot \n",
    "\\begin{pmatrix} \\ x \\\\ \\ y \\\\ 1 \\\\ \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "$$\n",
    "\\ (x', y') - \\ new \\ coordinates \\\\\n",
    "\\ (x, y) - \\ old \\ coordinates \\\\ \n",
    "$$\n",
    "Чтобы найти эту матрицу преобразования, OpenCV предоставляет функцию **cv2.getRotationMatrix2D()**. Ниже приведены несколько примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:43:56.735281Z",
     "start_time": "2020-09-26T17:43:55.965083Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "M1 = cv2.getRotationMatrix2D((0, 0), 25, scale=1.0)\n",
    "M2 = cv2.getRotationMatrix2D((300, 700), -15, scale=0.75)\n",
    "M3 = cv2.getRotationMatrix2D((300, 100), 45, scale=2.0)\n",
    "\n",
    "print(M1)\n",
    "\n",
    "## визуализация\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "dst1 = cv2.warpAffine(image.copy(), M1, (cols * 2, rows * 2))\n",
    "ax1.imshow(dst1)\n",
    "ax1.grid()\n",
    "ax1.set_title('M1 преоразование', fontsize=15)\n",
    "\n",
    "dst2 = cv2.warpAffine(image.copy(), M2, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "ax2.set_title('M2 преоразование', fontsize=15)\n",
    "\n",
    "dst3 = cv2.warpAffine(image.copy(), M3, (cols * 2, rows * 2))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid()\n",
    "ax3.set_title('M3 преоразование', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Контрольные вопросы:***\n",
    "Как сделать поворт изображения без обрезаний краев? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трансформация точек\n",
    "При аффинном преобразовании все параллельные линии в исходном изображении все еще будут параллельны в выходном изображении. Чтобы найти матрицу преобразования, нам нужны три точки из входного изображения и их соответствующие местоположения в выходном изображении. Затем **cv2.getAffineTransform()** создаст матрицу $2\\times 3$, которая должна быть передана в **cv2.warpAffine()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T18:07:01.970029Z",
     "start_time": "2020-09-26T18:07:01.558044Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "h, w, _ = image.shape\n",
    "\n",
    "pts1 = np.float32([[50, 50], [400, 50], [50, 200]])\n",
    "pts2 = np.float32([[100, 100], [200, 20], [100, 250]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2) \n",
    "print(f'Матрица перехода: \\n{M}')\n",
    "\n",
    "dst = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax1.grid()\n",
    "ax1.scatter(*pts1.T, color='g', s=100)\n",
    "\n",
    "ax2.set_title('M преобразование', fontsize=15)\n",
    "ax2.imshow(dst)\n",
    "ax2.grid()\n",
    "ax2.scatter(*pts2.T, color='g', s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перспектива\n",
    "\n",
    "На самом деле, идея очень простая: параллельный перенос не является линейной операцией в двумерном пространстве.\n",
    "Поэтому мы погружаем наше двумерное пространство в трёхмерное (добавив единицу в третью компоненту). Это означает, что наше двумерное пространство это плоскость z=1 внутри трёхмерного. Затем мы делаем линейное преобразование в трёхмерном пространстве и проецируем всё трехмерное пространство обратно на нашу физическую плоскость. Параллельный перенос от этого не стал линеен, но пайплайн всё же прост.\n",
    "\n",
    "\n",
    "\n",
    "Как именно мы проецируем трёхмерное пространство обратно в нашу плоскость? Очень просто:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z\\end{pmatrix} \\rightarrow \\begin{pmatrix} x/z \\\\ y/z \\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "Итак, если мы хотим построить центральную перспективу, находящейся на оси z на расстоянии c от начала координат, то сначала мы погружаем трёхмерные точки в четырёхмерное пространство, добавив 1. Затем умножаем на следующую матрицу и проецируем результат обратно в 3D:\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z\\end{pmatrix} \\rightarrow \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} 1 && 0 && 0 && 0 \\\\ 0 && 1 && 0 && 0 \\\\ 0 && 0 && 1 && 0 \\\\ 0 && 0 && -1/c && 1\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1\\end{pmatrix} = \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 - z/c\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 - z/c\\end{pmatrix} \\rightarrow \\begin{pmatrix} \\frac{x}{1-z/c} \\\\ \\frac{y}{1-z/c} \\\\ \\frac{z}{1-z/c}\\end{pmatrix}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для преобразования перспективы вам понадобится матрица преобразования $3\\times3$. Прямые линии останутся прямыми даже после трансформации. Чтобы найти эту матрицу преобразования, вам нужно $4$ точки на входном изображении и соответствующие точки на выходном изображении. Среди этих $4$ точек $3$ из них не должны быть коллинеарными. Тогда матрица преобразования может быть найдена функцией **cv2.getPerspectiveTransform()**. Затем примените **cv2.warpPerspective()** с этой матрицей преобразования $3\\times3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T17:50:15.291935Z",
     "start_time": "2020-09-26T17:50:14.713904Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Раземер исходного изображения:', image.shape)\n",
    "rows, cols, _ = image.shape\n",
    "\n",
    "pts1 = np.float32([[200, 100], [450, 100],[200, 400], [450, 400]])\n",
    "pts2 = np.float32([[0, 0],[cols/2, 0],[0, rows], [cols, rows]]) \n",
    "pts3 = np.float32([[0, 0],[cols, 0],[0, rows], [cols, rows/2]]) \n",
    "\n",
    "M1 = cv2.getPerspectiveTransform(pts1, pts2) \n",
    "M2 = cv2.getPerspectiveTransform(pts1, pts3) \n",
    "\n",
    "print(M1)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 3, figsize=(20,8))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение', fontsize=15)\n",
    "ax1.imshow(image)\n",
    "ax1.grid()\n",
    "ax1.scatter(*pts1.T, color='g', s=100)\n",
    "\n",
    "ax2.set_title('M1 преобразование', fontsize=15)\n",
    "dst2 = cv2.warpPerspective(image, M1, (cols, rows))\n",
    "ax2.imshow(dst2)\n",
    "ax2.grid()\n",
    "\n",
    "ax3.set_title('M2 преобразование', fontsize=15)\n",
    "dst3 = cv2.warpPerspective(image, M2, (cols, rows))\n",
    "ax3.imshow(dst3)\n",
    "ax3.grid();"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
